---
phase: 05-metrics-analysis-report
plan: 03
type: execute
depends_on: ["05-02"]
files_modified: [src/bsa/analysis/tables.py, src/bsa/analysis/__init__.py]
domain: python
---

<objective>
Create table generation module for summarizing experiment results in tabular format.

Purpose: Generate LaTeX/Markdown tables summarizing metrics, model comparisons, and ablation results. Tables should be publication-ready and save to results/tables/. This enables concise presentation of results in reports.

Output: TableGenerator class with methods for different table types, integration with analysis pipeline.
</objective>

<execution_context>
~/.cursor/get-shit-done/workflows/execute-plan.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-metrics-analysis-report/05-02-SUMMARY.md
@src/bsa/analysis/aggregate.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TableGenerator class</name>
  <files>src/bsa/analysis/tables.py, src/bsa/analysis/__init__.py</files>
  <action>
    Create `src/bsa/analysis/tables.py` with `TableGenerator` class that:
    
    1. Initializes with aggregated results DataFrame
    
    2. Implements `generate_summary_table()` method:
       - Creates summary table comparing models across conditions
       - Rows: Models (reactive, goal_only, belief_pf)
       - Columns: Key metrics (AUROC, detection latency, task completion, etc.)
       - Includes confidence intervals
       - Returns formatted table (Markdown or LaTeX)
    
    3. Implements `generate_detection_table()` method:
       - Focuses on false-belief detection metrics
       - Compares AUROC, detection latency, FPR across models
       - Shows statistical significance (if applicable)
       - Returns formatted table
    
    4. Implements `generate_task_performance_table()` method:
       - Focuses on task performance metrics
       - Compares completion rates, wasted actions, efficiency
       - Shows improvement over baselines
       - Returns formatted table
    
    5. Implements `generate_ablation_table()` method:
       - Summarizes ablation study results
       - Shows how parameters affect performance
       - Returns formatted table
    
    6. Implements `generate_intervention_table()` method:
       - Focuses on intervention quality metrics
       - Compares precision/recall, over/under-correction
       - Returns formatted table
    
    7. Table formatting:
       - Supports Markdown format (for GitHub/reports)
       - Supports LaTeX format (for papers)
       - Includes proper formatting (bold headers, alignment, etc.)
       - Handles missing values gracefully
    
    Export `TableGenerator` from `src/bsa/analysis/__init__.py`.
    
    Ensure tables are well-formatted and publication-ready.
  </action>
  <verify>
    Run `python -c "from src.bsa.analysis import TableGenerator; print('Import OK')"` - should import successfully.
    Run `python -c "from src.bsa.analysis.tables import TableGenerator; import pandas as pd; df = pd.read_parquet('results/metrics/main_experiment/results.parquet'); table_gen = TableGenerator(df); print('TableGenerator created')"` - should create table generator without errors.
  </verify>
  <done>TableGenerator exists, can generate all required table types</done>
</task>

<task type="auto">
  <name>Task 2: Implement generate_tables() function</name>
  <files>src/bsa/analysis/tables.py</files>
  <action>
    Implement `generate_tables()` function that:
    
    1. Takes config dictionary and aggregated results DataFrame
    2. Creates TableGenerator instance
    3. Generates all required tables:
       - Summary table
       - Detection metrics table
       - Task performance table
       - Intervention quality table
       - Ablation table (if ablation results available)
    4. Saves tables to output directory:
       - Markdown format: `results/tables/summary.md`, etc.
       - LaTeX format: `results/tables/summary.tex`, etc.
    5. Returns list of generated table file paths
    
    This function is called by analysis pipeline.
    
    Ensure tables are saved in both Markdown and LaTeX formats for flexibility.
  </action>
  <verify>
    Run `python -c "from src.bsa.analysis.tables import generate_tables; import pandas as pd; df = pd.read_parquet('results/metrics/main_experiment/results.parquet'); generate_tables({}, df, 'results/tables')"` - should generate tables successfully.
  </verify>
  <done>generate_tables() function implemented, saves tables correctly</done>
</task>

<task type="auto">
  <name>Task 3: Add statistical significance testing</name>
  <files>src/bsa/analysis/tables.py</files>
  <action>
    Add statistical significance testing to table generation:
    
    1. Implement `_compute_statistical_significance()` method:
       - Compares models using appropriate statistical tests
       - For continuous metrics: t-test or Mann-Whitney U test
       - For binary metrics: chi-square test
       - Returns p-values and significance indicators
    
    2. Add significance indicators to tables:
       - Asterisks (*, **, ***) for significance levels
       - Footnotes explaining significance levels
       - Only show when comparing models (not for single model)
    
    3. Handle multiple comparisons:
       - Bonferroni correction (optional)
       - Clear documentation of test used
    
    This makes tables more informative and publication-ready.
  </action>
  <verify>
    Run `python -c "from src.bsa.analysis.tables import TableGenerator; import pandas as pd; df = pd.read_parquet('results/metrics/main_experiment/results.parquet'); table_gen = TableGenerator(df); table = table_gen.generate_summary_table(); print('Table generated:', len(table) > 0)"` - should generate table with significance indicators.
  </verify>
  <done>Statistical significance testing added to tables</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] TableGenerator can generate all required table types
- [ ] Tables are well-formatted (Markdown and LaTeX)
- [ ] Statistical significance testing works
- [ ] Tables saved correctly to results/tables/
- [ ] Tables are publication-ready
</verification>

<success_criteria>

- TableGenerator implemented with all table types
- Tables are publication-ready (Markdown and LaTeX)
- Statistical significance testing included
- Ready for Plan 05-04 (Report generation)
  </success_criteria>

<output>
After completion, create `.planning/phases/05-metrics-analysis-report/05-03-SUMMARY.md`:

# Phase 5 Plan 3: Table Generation Summary

**Implemented table generation module for summarizing results**

## Accomplishments

- Created TableGenerator class
- Implemented all required table types (summary, detection, task performance, intervention, ablation)
- Publication-ready formatting (Markdown and LaTeX)
- Statistical significance testing

## Files Created/Modified

- `src/bsa/analysis/tables.py` - TableGenerator class
- `src/bsa/analysis/__init__.py` - Export TableGenerator

## Decisions Made

- Table formats: Markdown (for GitHub/reports) and LaTeX (for papers)
- Statistical tests: t-test/Mann-Whitney for continuous, chi-square for binary
- Significance indicators: Asterisks (*, **, ***) with footnotes
- Table structure: Models as rows, metrics as columns

## Issues Encountered

[Any issues with table formatting, statistical tests, etc.]

## Next Step

Ready for 05-04-PLAN.md (Report generation)
</output>
