---
phase: 06-tests-ci
plan: 01
type: execute
depends_on: []
files_modified: [tests/test_episode_generators.py, tests/test_particle_filter.py, tests/test_inference.py]
domain: python
---

<objective>
Create comprehensive unit tests for core components: episode generators, particle filter, and inference modules.

Purpose: Ensure core functionality works correctly with deterministic tests. These tests form the foundation for integration tests and CI verification. Focus on testing episode generation logic, particle filter behavior, and inference accuracy.

Output: Test files covering episode generators (GridHouse and VirtualHome), particle filter, goal inference, belief inference, and likelihood models.
</objective>

<execution_context>
~/.cursor/get-shit-done/workflows/execute-plan.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/bsa/envs/gridhouse/episode_generator.py
@src/bsa/envs/virtualhome/episode_generator.py
@src/bsa/inference/particle_filter.py
@src/bsa/inference/goal.py
@src/bsa/inference/belief.py
@src/bsa/inference/likelihood.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create episode generator tests</name>
  <files>tests/test_episode_generators.py</files>
  <action>
    Create `tests/test_episode_generators.py` with comprehensive tests for episode generators:
    
    1. **GridHouseEpisodeGenerator tests**:
       - `test_generate_episode()`: Test basic episode generation
       - `test_episode_structure()`: Verify episode has correct structure (episode_id, goal_id, steps, metadata)
       - `test_intervention_applied()`: Test that intervention is applied at tau timestep
       - `test_false_belief_created()`: Verify false belief is created (human belief != true location after intervention)
       - `test_belief_tracking()`: Test human agent belief updates correctly
       - `test_deterministic_seeding()`: Test that same seed produces same episode
       - `test_multiple_episodes()`: Test generate_episodes() function
       - `test_episode_saving()`: Test saving episodes to Parquet/JSONL
    
    2. **VirtualHomeEpisodeGenerator tests** (skip if VirtualHome not available):
       - Same tests as GridHouse but for VirtualHome
       - Test VirtualHome-specific features
    
    3. Use pytest fixtures for:
       - Environment instances
       - Episode generators
       - Sample tasks
    
    4. Ensure tests are deterministic (use fixed seeds)
    5. Test edge cases:
       - Empty task critical objects
       - Invalid tau values
       - No intervention scenarios
    
    Export test classes: `TestGridHouseEpisodeGenerator`, `TestVirtualHomeEpisodeGenerator`.
  </action>
  <verify>
    Run `pytest tests/test_episode_generators.py -v` - should run all tests successfully.
    Run `pytest tests/test_episode_generators.py::TestGridHouseEpisodeGenerator -v` - should test GridHouse generator.
  </verify>
  <done>Episode generator tests implemented, covering generation, intervention, belief tracking, and serialization</done>
</task>

<task type="auto">
  <name>Task 2: Create particle filter tests</name>
  <files>tests/test_particle_filter.py</files>
  <action>
    Create `tests/test_particle_filter.py` with comprehensive tests for ParticleFilter:
    
    1. **Initialization tests**:
       - `test_initialization()`: Test particle filter initializes with correct number of particles
       - `test_uniform_initialization()`: Verify initial particles are uniformly distributed
       - `test_initial_goal_distribution()`: Test initial goal distribution is uniform
    
    2. **Update tests**:
       - `test_update_with_action()`: Test particle weighting based on action likelihood
       - `test_resampling()`: Test systematic resampling maintains particle count
       - `test_particle_weights()`: Verify weights are normalized correctly
    
    3. **Belief extraction tests**:
       - `test_get_belief_distribution()`: Test goal distribution extraction
       - `test_get_object_location_beliefs()`: Test object location belief extraction
       - `test_get_most_likely_goal()`: Test most likely goal identification
       - `test_get_most_likely_locations()`: Test most likely object locations
    
    4. **Edge cases**:
       - `test_empty_particles()`: Handle empty particle list
       - `test_single_particle()`: Test with single particle
       - `test_all_zero_weights()`: Handle degenerate case (all weights zero)
    
    5. **Deterministic behavior**:
       - `test_deterministic_with_seed()`: Same seed produces same results
       - `test_resampling_deterministic()`: Resampling is deterministic with seed
    
    Use pytest fixtures for:
       - Sample likelihood models
       - Sample actions and observations
       - Sample goals and object locations
    
    Ensure tests verify correctness of particle filter algorithm.
  </action>
  <verify>
    Run `pytest tests/test_particle_filter.py -v` - should run all tests successfully.
    Check test coverage includes all ParticleFilter methods.
  </verify>
  <done>Particle filter tests implemented, covering initialization, update, resampling, and belief extraction</done>
</task>

<task type="auto">
  <name>Task 3: Create inference module tests</name>
  <files>tests/test_inference.py</files>
  <action>
    Create `tests/test_inference.py` with tests for inference modules:
    
    1. **GoalInference tests**:
       - `test_initialization()`: Test goal inference initializes with uniform distribution
       - `test_update_with_action()`: Test goal distribution updates based on action
       - `test_get_goal_distribution()`: Test distribution retrieval
       - `test_get_most_likely_goal()`: Test most likely goal identification
       - `test_convergence()`: Test goal inference converges to correct goal
    
    2. **BeliefInference tests**:
       - `test_initialization()`: Test belief inference initializes particle filter
       - `test_update()`: Test belief updates with observations
       - `test_detect_false_belief()`: Test false-belief detection logic
       - `test_get_belief_state()`: Test belief state extraction
    
    3. **LikelihoodModel tests**:
       - `test_rule_based_likelihood()`: Test rule-based likelihood computation
       - `test_action_likelihood()`: Test P(action | goal, beliefs) computation
       - `test_edge_cases()`: Test likelihood with missing data
    
    4. Use pytest fixtures for:
       - Sample tasks
       - Sample actions
       - Sample observations
       - Sample belief states
    
    5. Ensure tests verify inference correctness and convergence.
  </action>
  <verify>
    Run `pytest tests/test_inference.py -v` - should run all tests successfully.
    Check test coverage includes all inference modules.
  </verify>
  <done>Inference module tests implemented, covering goal inference, belief inference, and likelihood models</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Episode generator tests pass
- [ ] Particle filter tests pass
- [ ] Inference module tests pass
- [ ] Tests are deterministic (use seeds)
- [ ] Tests cover edge cases
- [ ] Test coverage >70% for tested modules
</verification>

<success_criteria>

- Comprehensive unit tests for episode generators, particle filter, and inference modules
- Tests are deterministic and cover edge cases
- Ready for Plan 06-02 (Helper agent tests)
  </success_criteria>

<output>
After completion, create `.planning/phases/06-tests-ci/06-01-SUMMARY.md`:

# Phase 6 Plan 1: Core Component Tests Summary

**Implemented comprehensive unit tests for core components**

## Accomplishments

- Created episode generator tests (GridHouse and VirtualHome)
- Created particle filter tests
- Created inference module tests (goal inference, belief inference, likelihood models)
- Tests are deterministic and cover edge cases

## Files Created/Modified

- `tests/test_episode_generators.py` - Episode generator tests
- `tests/test_particle_filter.py` - Particle filter tests
- `tests/test_inference.py` - Inference module tests

## Decisions Made

- Test framework: pytest (already configured)
- Test structure: Unit tests for individual components
- Deterministic testing: Use fixed seeds for reproducibility
- Edge case coverage: Test empty inputs, single particles, degenerate cases

## Issues Encountered

[Any issues with test implementation, edge cases, etc.]

## Next Step

Ready for 06-02-PLAN.md (Helper agent tests)
</output>
