---
phase: 04-experiment-harness
plan: 01
type: execute
depends_on: []
files_modified: [src/bsa/experiments/runner.py, src/bsa/experiments/__init__.py, configs/experiments/exp_main.yaml]
domain: python
---

<objective>
Implement core experiment runner that executes experiments with different helper models and conditions.

Purpose: Enable automated execution of experiments comparing different helper agents (reactive, goal-only, belief-sensitive) across different conditions (control, false-belief, seen-relocation). This is the foundation for the experiment harness.

Output: ExperimentRunner class that can run experiments, save results, and integrate with episode generators and helper agents.
</objective>

<execution_context>
~/.cursor/get-shit-done/workflows/execute-plan.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/bsa/experiments/run_experiment.py
@src/bsa/agents/helper/__init__.py
@src/bsa/envs/gridhouse/episode_generator.py
@src/bsa/envs/virtualhome/episode_generator.py
@configs/experiments/exp_main.yaml
@src/bsa/common/config.py
@src/bsa/common/types.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ExperimentRunner class</name>
  <files>src/bsa/experiments/runner.py, src/bsa/experiments/__init__.py</files>
  <action>
    Create `src/bsa/experiments/runner.py` with `ExperimentRunner` class that:
    
    1. Initializes with experiment configuration (models, conditions, num_runs, seed)
    2. Implements `run_experiment()` method that:
       - Loads episode generator (GridHouse or VirtualHome based on config)
       - For each model (reactive, goal_only, belief_pf):
         - Instantiates helper agent from config
         - For each condition (control, false_belief, seen_relocation):
           - Generates or loads episodes
           - Runs helper agent on episodes (evaluates performance)
           - Collects metrics (task completion, wasted actions, false-belief detection, etc.)
           - Saves results
       - Returns experiment results
    
    3. Implements `_create_helper_agent()` method that instantiates helper agents from config:
       - ReactiveHelper: No config needed
       - GoalOnlyHelper: Uses task list from environment
       - BeliefSensitiveHelper: Uses task list + particle filter config (num_particles, etc.)
    
    4. Implements `_evaluate_episode()` method that:
       - Runs helper agent on episode step-by-step
       - Tracks metrics: actions taken, false-belief detection, task completion, etc.
       - Returns episode metrics
    
    5. Implements `_save_results()` method that saves experiment results to:
       - `results/metrics/{experiment_name}/` directory
       - Parquet format for metrics
       - JSON manifest with experiment metadata
    
    Export `ExperimentRunner` from `src/bsa/experiments/__init__.py`.
    
    Use deterministic seeding for reproducibility. Support both GridHouse and VirtualHome environments.
  </action>
  <verify>
    Run `python -c "from src.bsa.experiments import ExperimentRunner; print('Import OK')"` - should import successfully.
    Run `python -c "from src.bsa.experiments.runner import ExperimentRunner; config = {'models': ['reactive'], 'conditions': ['control'], 'num_runs': 1, 'seed': 42}; runner = ExperimentRunner(config); print('Runner created')"` - should create runner without errors.
  </verify>
  <done>ExperimentRunner class exists, can instantiate helper agents, can evaluate episodes, can save results</done>
</task>

<task type="auto">
  <name>Task 2: Integrate ExperimentRunner with CLI and episode generators</name>
  <files>src/bsa/experiments/run_experiment.py, src/bsa/cli.py</files>
  <action>
    Update `src/bsa/experiments/run_experiment.py` to:
    
    1. Implement `run_experiments()` function that:
       - Loads experiment config from YAML
       - Creates ExperimentRunner instance
       - Runs experiments
       - Saves results to output directory
    
    2. Implement `generate_episodes()` function that:
       - Loads generator config from YAML
       - Creates appropriate episode generator (GridHouse or VirtualHome)
       - Generates episodes and saves them
       - Returns list of generated episodes
    
    3. Update `reproduce()` function stub (will be completed in later plan)
    
    Update `src/bsa/cli.py` to ensure it correctly calls these functions.
    
    Ensure config loading works with YAML files in `configs/experiments/` and `configs/generator/`.
  </action>
  <verify>
    Run `python -m src.bsa.cli run --config configs/experiments/exp_main.yaml --output results/test` - should run experiments without errors (may take time).
    Run `python -m src.bsa.cli generate --config configs/generator/default.yaml --output data/episodes/test` - should generate episodes.
  </verify>
  <done>run_experiments() and generate_episodes() implemented, CLI integration works</done>
</task>

<task type="auto">
  <name>Task 3: Implement episode evaluation logic</name>
  <files>src/bsa/experiments/runner.py</files>
  <action>
    Implement `_evaluate_episode()` method in ExperimentRunner that:
    
    1. Takes episode and helper agent as inputs
    2. Resets helper agent state
    3. Iterates through episode steps:
       - Gets helper observation from step
       - Calls helper.plan_action() to get action
       - Calls helper.update_belief() with human action and observation
       - Tracks metrics:
         - Actions taken by helper
         - False-belief detection (if applicable)
         - Task completion status
         - Wasted actions (human actions that don't progress toward goal)
         - Intervention timing and type
    
    4. Computes episode-level metrics:
       - Task completed: boolean
       - Num steps to completion: int (or None if not completed)
       - Num wasted actions: int
       - False-belief detected: boolean (for belief-sensitive helper)
       - Detection latency: int (timestep when false belief detected, or None)
       - Num helper interventions: int
       - Helper action types: list of action types
    
    5. Returns dictionary with all metrics
    
    Ensure evaluation is deterministic (use seeds, deterministic helper behavior).
  </action>
  <verify>
    Run `python -c "from src.bsa.experiments.runner import ExperimentRunner; from src.bsa.envs.gridhouse import GridHouseEnvironment, GridHouseEpisodeGenerator; env = GridHouseEnvironment(seed=42); gen = GridHouseEpisodeGenerator(env, seed=42); episode = gen.generate_episode(); runner = ExperimentRunner({'models': ['reactive'], 'conditions': ['control'], 'num_runs': 1, 'seed': 42}); metrics = runner._evaluate_episode(episode, runner._create_helper_agent('reactive')); print(f'Metrics: {metrics}')"` - should evaluate episode and return metrics.
  </verify>
  <done>Episode evaluation logic implemented, computes all required metrics</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] ExperimentRunner class exists and can be instantiated
- [ ] Helper agents can be created from config
- [ ] Episodes can be evaluated with helper agents
- [ ] Results can be saved to results/metrics/
- [ ] CLI commands (run, generate) work correctly
- [ ] Evaluation is deterministic (same seed = same results)
</verification>

<success_criteria>

- ExperimentRunner implemented and working
- Can run experiments with different models and conditions
- Episode evaluation computes required metrics
- Results saved correctly
- CLI integration works
- Ready for Plan 04-02 (Episode Evaluator enhancements)
  </success_criteria>

<output>
After completion, create `.planning/phases/04-experiment-harness/04-01-SUMMARY.md`:

# Phase 4 Plan 1: Experiment Runner Core Summary

**Implemented core experiment runner for automated experiment execution**

## Accomplishments

- Created ExperimentRunner class for running experiments
- Integrated with helper agents (reactive, goal-only, belief-sensitive)
- Implemented episode evaluation logic
- Results saving to results/metrics/
- CLI integration working

## Files Created/Modified

- `src/bsa/experiments/runner.py` - ExperimentRunner class
- `src/bsa/experiments/run_experiment.py` - Updated with run_experiments() and generate_episodes()
- `src/bsa/experiments/__init__.py` - Export ExperimentRunner
- `src/bsa/cli.py` - Already integrated (no changes needed)

## Decisions Made

- Experiment structure: models × conditions × runs
- Helper agent instantiation from config
- Episode evaluation approach (step-by-step simulation)
- Metrics to track (task completion, wasted actions, false-belief detection, etc.)
- Results storage format (Parquet + JSON manifest)

## Issues Encountered

[Any issues with helper agent integration, episode evaluation, etc.]

## Next Step

Ready for 04-02-PLAN.md (Episode Evaluator enhancements and detailed metrics)
</output>
