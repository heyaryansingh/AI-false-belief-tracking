---
phase: 01-core-interfaces-gridhouse
plan: 01
type: execute
depends_on: []
files_modified: [src/bsa/agents/human/scripted_human.py, src/bsa/agents/human/policies.py, src/bsa/agents/human/__init__.py]
---

<objective>
Implement human agent scripted policies that plan actions based on task goals and belief state about object locations.

Purpose: The human agent must exhibit realistic behavior - planning actions toward believed object locations, updating beliefs only when observing evidence, and holding false beliefs when objects move without observation.

Output: Scripted human agent with goal-directed planning and belief-based action selection.
</objective>

<execution_context>
~/.cursor/get-shit-done/workflows/execute-plan.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/bsa/common/types.py
@src/bsa/envs/gridhouse/env.py
@src/bsa/envs/gridhouse/tasks.py
@src/bsa/envs/gridhouse/episode_generator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create human agent base class and scripted policy interface</name>
  <files>src/bsa/agents/human/__init__.py, src/bsa/agents/human/scripted_human.py</files>
  <action>
Create ScriptedHumanAgent class in src/bsa/agents/human/scripted_human.py:
- Maintains current goal (Task object)
- Maintains belief state (Dict[str, ObjectLocation] - object_id -> believed location)
- Has method `plan_action(observation: Observation, task: Task, belief_state: Dict) -> Action`
- Has method `update_belief(observation: Observation, belief_state: Dict) -> None` that updates beliefs only when objects are observed
- Initialize with goal and initial belief state (matches true state initially)

The agent should:
- Plan actions toward believed locations of critical objects
- Use simple pathfinding (move toward target room/container)
- Open containers when near them
- Pickup objects when adjacent
- Update beliefs only when observing objects/containers (partial observability)

Use type hints throughout. Follow existing code style.
</action>
  <verify>python -c "from src.bsa.agents.human import ScriptedHumanAgent; from src.bsa.envs.gridhouse.tasks import get_task; agent = ScriptedHumanAgent(goal=get_task('prepare_meal')); print('Agent created')"</verify>
  <done>ScriptedHumanAgent class exists with plan_action and update_belief methods, type hints present</done>
</task>

<task type="auto">
  <name>Task 2: Implement goal-directed planning policy</name>
  <files>src/bsa/agents/human/policies.py</files>
  <action>
Create planning functions in src/bsa/agents/human/policies.py:
- `plan_next_action(agent_pos: Tuple[int, int], agent_room: str, task: Task, belief_state: Dict[str, ObjectLocation], visible_objects: List[str], visible_containers: List[str]) -> Action`

Planning logic:
1. Identify next critical object needed (from task.critical_objects)
2. Check if object is visible - if yes, move toward it and pickup
3. If not visible, check belief state for object location
4. Plan path: move toward believed room, open containers if needed, pickup object
5. Return appropriate Action (MOVE, OPEN, PICKUP, WAIT)

Use simple heuristic: distance-based selection (move toward closest target). Handle edge cases:
- Object already in hand (move to goal location)
- Container needs opening (OPEN action)
- Already at target (WAIT or next object)

Import Action from src.bsa.common.types. Use type hints.
</action>
  <verify>python -c "from src.bsa.agents.human.policies import plan_next_action; from src.bsa.envs.gridhouse.tasks import get_task; task = get_task('prepare_meal'); action = plan_next_action((5,5), 'kitchen', task, {}, [], []); print(f'Action: {action}')"</verify>
  <done>plan_next_action function exists and returns valid Action enum values</done>
</task>

<task type="auto">
  <name>Task 3: Integrate human agent into episode generator</name>
  <files>src/bsa/envs/gridhouse/episode_generator.py</files>
  <action>
Update GridHouseEpisodeGenerator to use ScriptedHumanAgent:
- Import ScriptedHumanAgent
- In __init__, create human_agent instance with goal
- In generate_episode, initialize agent with selected goal
- Replace _get_human_action stub with agent.plan_action() call
- Replace _update_human_belief stub with agent.update_belief() call
- Maintain human_belief_locations dict that tracks agent's belief state
- Ensure belief state is passed correctly to EpisodeStep

The human agent should:
- Start with correct initial beliefs (matching true state)
- Update beliefs only when observing objects
- Plan actions based on beliefs, not true state
- Create false beliefs when intervention occurs (object moves without observation)

Test that episode generation produces realistic human behavior.
</action>
  <verify>python -c "from src.bsa.envs.gridhouse import GridHouseEnvironment, GridHouseEpisodeGenerator; env = GridHouseEnvironment(seed=42); gen = GridHouseEpisodeGenerator(env, seed=42); ep = gen.generate_episode(goal_id='prepare_meal', tau=10); print(f'Episode generated: {len(ep.steps)} steps')"</verify>
  <done>Episode generator uses ScriptedHumanAgent, generates episodes with human actions based on beliefs</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `pytest tests/test_env_interface.py -v` passes
- [ ] Human agent can be instantiated and plan actions
- [ ] Episode generator produces episodes with human actions
- [ ] Human beliefs update only when objects are observed
- [ ] No import errors or type errors
</verification>

<success_criteria>

- ScriptedHumanAgent class implemented with belief tracking
- Goal-directed planning policy implemented
- Episode generator integrated with human agent
- Human actions reflect belief state, not true state
- Belief updates occur only on observation
- All code has type hints and docstrings

</success_criteria>

<output>
After completion, create `.planning/phases/01-core-interfaces-gridhouse/01-01-SUMMARY.md`:

# Phase 1 Plan 1: Human Agent Scripted Policies Summary

**Implemented human agent with goal-directed planning and belief-based action selection**

## Accomplishments

- Created ScriptedHumanAgent class with belief state tracking
- Implemented goal-directed planning policy (plan_next_action)
- Integrated human agent into episode generator
- Human agent plans actions based on beliefs, updates beliefs only on observation

## Files Created/Modified

- `src/bsa/agents/human/__init__.py` - Module exports
- `src/bsa/agents/human/scripted_human.py` - ScriptedHumanAgent class
- `src/bsa/agents/human/policies.py` - Planning policy functions
- `src/bsa/envs/gridhouse/episode_generator.py` - Integration with human agent

## Decisions Made

- Simple heuristic-based planning (distance-based) - sufficient for research purposes
- Belief state tracked as Dict[str, ObjectLocation] - matches EpisodeStep format
- Human agent updates beliefs only when objects are visible - enables false beliefs

## Issues Encountered

None

## Next Step

Ready for 01-02-PLAN.md (Episode generator core logic: belief updates and interventions)

</output>
